300
train loss:1.088373780202343
train loss:1.087135802909167
train loss:1.0777756951333033
train loss:1.058071059764509
train loss:1.08298312870573
train loss:1.042572325652193
train loss:1.0736827613626914
train loss:1.042771171374566
train loss:1.0212212271607144
train loss:1.0789201254596064
train loss:1.0607277365831276
train loss:1.0912460639040817
train loss:1.0594458854779776
train loss:1.051888868964098
train loss:1.0724559512342566
train loss:1.0830397984907096
train loss:1.063007307656862
train loss:1.0300437969675513
train loss:1.0954446764844878
train loss:1.067680085401075
train loss:1.0486935900582521
train loss:1.0332972334138064
train loss:1.0750564127155298
train loss:1.071263396239486
train loss:1.0020633986952605
train loss:1.0216009625377296
train loss:1.0006023240133777
train loss:1.0894809555728198
train loss:0.9554813488033116
train loss:0.9936571525588123
train loss:1.0504380690335586
train loss:1.0783232685934423
train loss:1.0152610922834082
train loss:1.0234147303200354
train loss:1.0314781596036626
train loss:1.0182969074099797
train loss:1.033880224029953
train loss:1.0418202030236159
train loss:0.9977525462937603
train loss:1.0196794373190903
train loss:0.9766543500098613
train loss:0.9371640518397952
train loss:1.0389955613191415
train loss:0.9698135555807593
train loss:0.9761219717018182
train loss:1.0005451492047799
train loss:0.9272690049878147
train loss:0.9567767320928001
train loss:0.9325751017396111
train loss:0.8818155577682042
train loss:0.8735339776488895
train loss:0.8663862254952847
train loss:0.8572260587109217
train loss:0.840751749156876
train loss:0.772044312616546
train loss:0.7898634581854432
train loss:0.7299623826839715
train loss:0.6689611686027441
train loss:0.7735574106714137
train loss:0.733014926486555
60
60
=== epoch:1, train acc:0.805, test acc:0.822 ===
train loss:0.6457049792081417
train loss:0.6822657592219192
train loss:0.6476464101331026
train loss:0.6937170811176453
train loss:0.6012972551044866
train loss:0.5941755984316142
train loss:0.5847895066030177
train loss:0.5639561776189651
train loss:0.5476207433973257
train loss:0.47156283012421096
train loss:0.4783361941277922
train loss:0.4859210900997467
train loss:0.576339761611723
train loss:0.49822153028293714
train loss:0.41465038192819587
train loss:0.5010759700754446
train loss:0.3375771368522658
train loss:0.4886642358536398
train loss:0.3676786016427267
train loss:0.4132546598167957
train loss:0.4119199097885955
train loss:0.3384294928861821
train loss:0.3251740586673093
train loss:0.46259268659451985
train loss:0.35473977166319764
train loss:0.3376673098075718
train loss:0.31507857344440543
train loss:0.2715100482077896
train loss:0.42178205037582406
train loss:0.3817760494700975
train loss:0.2655518579997996
train loss:0.34122434906173915
train loss:0.30526456997885504
train loss:0.37301319476166145
train loss:0.36027183320963985
train loss:0.22640397963625594
train loss:0.28081541014582617
train loss:0.30957707557386577
train loss:0.25921053878909117
train loss:0.31385885550195136
train loss:0.28453223621568374
train loss:0.25199441788997684
train loss:0.2056303747588983
train loss:0.40428477144861025
train loss:0.1923216194765514
train loss:0.3151501585979793
train loss:0.330894882619419
train loss:0.2119130266996341
train loss:0.1367032704273052
train loss:0.28698201090069747
train loss:0.26284603097479126
train loss:0.27135174016122043
train loss:0.17314374483498762
train loss:0.22066829726275178
train loss:0.2868894724889866
train loss:0.4083486968568167
train loss:0.27733559589855034
train loss:0.14299218375264638
train loss:0.2583756160717902
train loss:0.258875960611306
120
60
=== epoch:2, train acc:0.905, test acc:0.917 ===
train loss:0.2380042382746622
train loss:0.23416251099490043
train loss:0.2477471892206966
train loss:0.3343216936656088
train loss:0.30095747986193083
train loss:0.2201451401348439
train loss:0.28718853388021093
train loss:0.22955175046903625
train loss:0.2039745259045417
train loss:0.24405558440433125
train loss:0.25926044670294174
train loss:0.14198990952721222
train loss:0.22947014323269196
train loss:0.21060964925596312
train loss:0.2050110059568342
train loss:0.17114097674886392
train loss:0.14906428400967775
train loss:0.22860217706006458
train loss:0.2010693855877386
train loss:0.2764677961594644
train loss:0.19321453567551322
train loss:0.14154452916163093
train loss:0.23470414245929722
train loss:0.19508194356541034
train loss:0.15422002940376411
train loss:0.21471604955152962
train loss:0.20542944952204023
train loss:0.15764320042841876
train loss:0.28590200845579383
train loss:0.2548046595137564
train loss:0.17143636750058364
train loss:0.2197320559163406
train loss:0.20957637876856816
train loss:0.26880586480842344
train loss:0.14546564339476972
train loss:0.16097435151631154
train loss:0.19709267017451176
train loss:0.18966367692316777
train loss:0.2413505446450035
train loss:0.16376839136513094
train loss:0.13715723106912736
train loss:0.21631868044006372
train loss:0.25106735957740806
train loss:0.2235212726236567
train loss:0.16111623257408642
train loss:0.13910954534291534
train loss:0.20652557867341456
train loss:0.2452978865872453
train loss:0.10351416953636601
train loss:0.14449250671813238
train loss:0.16190381285563007
train loss:0.11190340535833831
train loss:0.12228706963860997
train loss:0.1747051955706469
train loss:0.11967475031081459
train loss:0.12502964514534473
train loss:0.12912684572578578
train loss:0.11524692519554745
train loss:0.15780032428874713
train loss:0.14460166106925232
180
60
=== epoch:3, train acc:0.945, test acc:0.945 ===
train loss:0.09016920654820822
train loss:0.1230485889680391
train loss:0.1197858636878853
train loss:0.13347668756003508
train loss:0.10156706828107621
train loss:0.1275235217277633
train loss:0.08741576950207448
train loss:0.2303711037716232
train loss:0.15879688315121057
train loss:0.1800959648652491
train loss:0.09616547142285765
train loss:0.12062476646936827
train loss:0.18777156595536362
train loss:0.12946971978405428
train loss:0.11514759495408931
train loss:0.16372320282101466
train loss:0.15638731284592386
train loss:0.08975401811857533
train loss:0.14521950796535857
train loss:0.15481870014439525
train loss:0.2231642022917932
train loss:0.13790084376880887
train loss:0.1280687903272323
train loss:0.08643437025112574
train loss:0.11434156814996595
train loss:0.09969861284321237
train loss:0.19056631453121736
train loss:0.08042608229519133
train loss:0.07465305651438024
train loss:0.05136688403375598
train loss:0.13738477302696803
train loss:0.07417661604627838
train loss:0.05742922459216421
train loss:0.10338482113771541
train loss:0.09244182853441878
train loss:0.08434584905948955
train loss:0.47680496124177857
train loss:0.13983131491846543
train loss:0.2084153901957355
train loss:0.263209244043823
train loss:0.09509728670675485
train loss:0.15082642608372057
train loss:0.11093963965176126
train loss:0.15014868318244903
train loss:0.1184333228249115
train loss:0.22226335184187004
train loss:0.1500000948593239
train loss:0.09240763964239637
train loss:0.1630529748658126
train loss:0.17277394640069535
train loss:0.12527239874211632
train loss:0.12851928808416666
train loss:0.18280400764881807
train loss:0.10741231042721078
train loss:0.05635701947635427
train loss:0.07137571772610422
train loss:0.13197157092610734
train loss:0.08120682949100413
train loss:0.09635040024575846
train loss:0.060542835705616034
240
60
=== epoch:4, train acc:0.965, test acc:0.955 ===
train loss:0.1328819678850322
train loss:0.1063469238289453
train loss:0.0726782782824083
train loss:0.11160343963525704
train loss:0.0911779329298101
train loss:0.1310331389282748
train loss:0.06555267971844161
train loss:0.11406947768873224
train loss:0.04922049018274617
train loss:0.10670741637536164
train loss:0.12802983242495267
train loss:0.07542051450149825
train loss:0.10242777942556419
train loss:0.04805869930450864
train loss:0.11990712052465953
train loss:0.06588767349451585
train loss:0.10067703931880834
train loss:0.07122888740276016
train loss:0.06281832423306496
train loss:0.13810877991953266
train loss:0.1042484987286201
train loss:0.07390575687972996
train loss:0.05608817815065412
train loss:0.08790053367480759
train loss:0.07071282088902917
train loss:0.07985198829236212
train loss:0.10031209455062554
train loss:0.06896612603618228
train loss:0.06394204264353905
train loss:0.04225692467274318
train loss:0.03592556721687952
train loss:0.05124362122353653
train loss:0.047520502465980316
train loss:0.15124748802814839
train loss:0.03492902909733513
train loss:0.058383410874960656
train loss:0.06176913821538479
train loss:0.10581379290196623
train loss:0.0858997612036334
train loss:0.05677537406519282
train loss:0.14538684319386913
train loss:0.046841408187791075
train loss:0.10987730424412105
train loss:0.05016810066614699
train loss:0.04275704781752975
train loss:0.05754242665187555
train loss:0.1254270620068296
train loss:0.05414649979377653
train loss:0.13925840903182116
train loss:0.10442298660017472
train loss:0.06016179888808816
train loss:0.12049086237580342
train loss:0.04184419015956395
train loss:0.05140554126530548
train loss:0.1046272934269103
train loss:0.06794257387198703
train loss:0.09014368958071038
train loss:0.0832552469362358
train loss:0.05227737563357793
train loss:0.09236025153754004
300
60
=== epoch:5, train acc:0.976, test acc:0.959 ===
=============== Final Test Accuracy ===============
test acc:0.9529801324503311
Saved Network Parameters!
300
train loss:1.0499286954001215
train loss:1.0302043775151413
train loss:1.1066850481785955
train loss:1.0304909470429804
train loss:1.057475115881883
train loss:1.063724971680507
train loss:1.0418653982752586
train loss:1.037053227255245
train loss:1.0485138405721441
train loss:1.0250986435019334
train loss:0.984272575053603
train loss:1.036659255739191
train loss:1.0915744880954847
train loss:1.0578852164553778
train loss:1.0583542846697802
train loss:1.0379646473591206
train loss:1.0443286213406469
train loss:1.050567089812258
train loss:1.0643275959821914
train loss:1.0443690592384285
train loss:1.0597970892647
train loss:1.038259637573433
train loss:1.0044683022860232
train loss:0.9724068945430555
train loss:1.0816029199446513
train loss:0.9467967167368684
train loss:1.0285674938362064
train loss:1.0218433486164082
train loss:1.0405246028165223
train loss:1.019692356309728
train loss:0.9597734245608984
train loss:1.00038816125646
train loss:0.9863106332312006
train loss:0.9888365386581238
train loss:1.0065239878466825
train loss:0.9404735965152355
train loss:0.9854125969296832
train loss:0.9004059538194525
train loss:0.9266847442150792
train loss:0.9133985513243345
train loss:0.9177843611378671
train loss:0.8372134285814622
train loss:0.8882598751950301
train loss:0.8267550616780909
train loss:0.7934770655036907
train loss:0.7521565050291241
train loss:0.7378702306277028
train loss:0.7106110470225336
train loss:0.662058848569941
train loss:0.6922895310851298
train loss:0.6555569783019054
train loss:0.6947662937887084
train loss:0.623110627447017
train loss:0.6357105991414899
train loss:0.541253715640963
train loss:0.48998648176754644
train loss:0.5247045402092932
train loss:0.587315316369953
train loss:0.5598658880225085
train loss:0.568687813013496
60
60
=== epoch:1, train acc:0.747, test acc:0.752 ===
train loss:0.5219416434876321
train loss:0.5440468491535934
train loss:0.5792779149896952
train loss:0.6224219009522327
train loss:0.5429935197459037
train loss:0.48003409118352913
train loss:0.544275796763228
train loss:0.44426936203068346
train loss:0.4282001486369763
train loss:0.41670390590942114
train loss:0.5883013444786687
train loss:0.4885335407575244
train loss:0.3866394376684519
train loss:0.4307115610144956
train loss:0.5431984966956266
train loss:0.4709234814480196
train loss:0.47129565055536177
train loss:0.4968144560267841
train loss:0.5110380452161839
train loss:0.3871792522018378
train loss:0.35279232310372244
train loss:0.2750127530286956
train loss:0.49602915806544123
train loss:0.4117978357940364
train loss:0.3434436572426606
train loss:0.3865748112300695
train loss:0.4647447720605423
train loss:0.36456954179429574
train loss:0.4163320516215213
train loss:0.3599912037638684
train loss:0.2794457602151172
train loss:0.3687563247333894
train loss:0.28827785731958583
train loss:0.39712139657622914
train loss:0.35375867816290024
train loss:0.23061695234140925
train loss:0.4429641356941898
train loss:0.34544392915526534
train loss:0.874105907253036
train loss:0.3776874429397034
train loss:0.4151995676776154
train loss:0.599747429458707
train loss:0.4042286201404233
train loss:0.3271381180891554
train loss:0.31036292059799686
train loss:0.3319489411188287
train loss:0.25528622630102105
train loss:0.2613866496136649
train loss:0.3098843948858837
train loss:0.4559426287906223
train loss:0.390556058384167
train loss:0.3613763694910302
train loss:0.3751876389499041
train loss:0.28159439690303056
train loss:0.2939621938831818
train loss:0.3410393524508673
train loss:0.30983858589034513
train loss:0.2765548352379501
train loss:0.21386185133300006
train loss:0.35227274638610057
120
60
=== epoch:2, train acc:0.926, test acc:0.917 ===
train loss:0.3914552262893621
train loss:0.25528933870065507
train loss:0.2654731788944985
train loss:0.2447851403052125
train loss:0.22100710346570612
train loss:0.2785062977245897
train loss:0.1741297631112374
train loss:0.2027291322400966
train loss:0.3118090541231648
train loss:0.2588784908314405
train loss:0.26024409600682874
train loss:0.19525344878057338
train loss:0.2960598328108082
train loss:0.30867526286113217
train loss:0.2386841517880811
train loss:0.2628186395648093
train loss:0.2622210092677425
train loss:0.12464897150456115
train loss:0.16325407466218714
train loss:0.20690011828586194
train loss:0.23974420696232449
train loss:0.1650962945208497
train loss:0.21218764473255544
train loss:0.21616135456020674
train loss:0.0982796959138589
train loss:0.15676542923655823
train loss:0.09521641623489811
train loss:0.08487184398357578
train loss:0.16841340879074232
train loss:0.22405027002844974
train loss:0.09864205203128196
train loss:0.2230802249966866
train loss:0.1600328091494817
train loss:0.19985351935525425
train loss:0.14705863975588293
train loss:0.18994940630834278
train loss:0.18775122915906725
train loss:0.16526535731834346
train loss:0.2512476182233603
train loss:0.11829307345936804
train loss:0.1957518722312722
train loss:0.14714115995930413
train loss:0.17055181787108037
train loss:0.14183204829651413
train loss:0.20831110259501412
train loss:0.11216534137303197
train loss:0.23104823461783178
train loss:0.07939093373360759
train loss:0.1611140831598819
train loss:0.14105552347907596
train loss:0.07928279020093566
train loss:0.16201017459099887
train loss:0.16664077328418647
train loss:0.13910273133718692
train loss:0.19129571574655913
train loss:0.1511980713301013
train loss:0.10646871011985144
train loss:0.13903117720099215
train loss:0.1453015582222208
train loss:0.1396578777679342
180
60
=== epoch:3, train acc:0.957, test acc:0.954 ===
train loss:0.12144201606110513
train loss:0.24172542087626428
train loss:0.1606439534679473
train loss:0.08621490266020558
train loss:0.12155126585068049
train loss:0.13669486882157442
train loss:0.15725467367584262
train loss:0.14871027476122264
train loss:0.16980926105404065
train loss:0.1358549541714958
train loss:0.15999312621097553
train loss:0.06564597549573627
train loss:0.13268988329327913
train loss:0.09141931851566792
train loss:0.13886624844739726
train loss:0.08141414032732429
train loss:0.11041145810579221
train loss:0.1811802631347163
train loss:0.13445041034075125
train loss:0.13436077033992233
train loss:0.1603510402179512
train loss:0.13756758574413205
train loss:0.11603564308239708
train loss:0.07396837636606053
train loss:0.20548381281278238
train loss:0.16287733847015398
train loss:0.09066588985435273
train loss:0.09703232238993553
train loss:0.10410568881898578
train loss:0.10589752099962414
train loss:0.1410619694350272
train loss:0.07397040353133491
train loss:0.1270844420467549
train loss:0.13404814080525898
train loss:0.08251368853619581
train loss:0.11067411979220891
train loss:0.09867611347177582
train loss:0.07167073273351589
train loss:0.04049747495281113
train loss:0.1546910340507676
train loss:0.11666722068961598
train loss:0.17599808459498514
train loss:0.051927499449593045
train loss:0.061193295814708025
train loss:0.12185149442535347
train loss:0.09729225920835034
train loss:0.13488216939538808
train loss:0.07480058554279052
train loss:0.03436270092505327
train loss:0.0687287742639242
train loss:0.09713863549907156
train loss:0.0833345291072308
train loss:0.11388817225981482
train loss:0.1054988254331141
train loss:0.05546902650183096
train loss:0.08554528124879605
train loss:0.06920392743023551
train loss:0.04350954321967865
train loss:0.10278895933779694
train loss:0.11243815233508654
240
60
=== epoch:4, train acc:0.969, test acc:0.964 ===
train loss:0.07525282084354132
train loss:0.09448548550136655
train loss:0.1025046961355451
train loss:0.055990794781556025
train loss:0.0538457387101747
train loss:0.06379206171139018
train loss:0.10309735518442276
train loss:0.08895821588115
train loss:0.08369695917738547
train loss:0.05339900717913767
train loss:0.08325890955721178
train loss:0.06949788595286582
train loss:0.14387345640677973
train loss:0.06251451596833524
train loss:0.05732047599792418
train loss:0.05120297268444376
train loss:0.08696924299954707
train loss:0.056259661523286944
train loss:0.11106987359518601
train loss:0.06027483706906042
train loss:0.06130703359983924
train loss:0.0956373914913025
train loss:0.10291988044288232
train loss:0.07499317187854611
train loss:0.035678282801653236
train loss:0.06190600932504213
train loss:0.0313292986066224
train loss:0.11400542193687677
train loss:0.035119204779211786
train loss:0.1812565154419725
train loss:0.0542532375475734
train loss:0.03282525551737231
train loss:0.07844171351369814
train loss:0.062011878955781245
train loss:0.11794922580414807
train loss:0.06036153083441285
train loss:0.029772557399633935
train loss:0.08943367358019443
train loss:0.10567819348688744
train loss:0.13456477103629272
train loss:0.040780623412527056
train loss:0.08595729817178309
train loss:0.10374824331855054
train loss:0.06362975310352041
train loss:0.09462898390312093
train loss:0.07730969768456566
train loss:0.0971736383044877
train loss:0.06611838187937154
train loss:0.1638011896413612
train loss:0.030163278527242855
train loss:0.030572302445632818
train loss:0.04016009923924912
train loss:0.05635386163416574
train loss:0.04278755942237982
train loss:0.04074600745487031
train loss:0.05391476232296823
train loss:0.06015107954719257
train loss:0.05880446467011616
train loss:0.14781230787493846
train loss:0.035696238441817164
300
60
=== epoch:5, train acc:0.983, test acc:0.971 ===
=============== Final Test Accuracy ===============
test acc:0.9596026490066225
Saved Network Parameters!
